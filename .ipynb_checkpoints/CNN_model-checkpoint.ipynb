{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data which is being used for this assignment is that of Images belonging to Adidas and Starbucks. This is our project data. Our project revolves around the concept of logo recognition of various brands from a wide range of images which contain the logos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Image Classifier Using Convolutional Neural Network\n",
    "\n",
    "\n",
    "The goal of this image classifier is to identify class to which an image belongs to. The way I am going to achieve it is by training an artificial neural network on few thousand images of adidas and starbcuks and make the NN(Neural Network) learn to predict which class the image belongs to, next time it sees an image having adidas or starbucks in it.\n",
    "\n",
    "This model can be trained on any type of classes like for example a doctor can train Neural Network that can take a brain scan as an input and predict if the scan contains tumor or not.\n",
    "\n",
    "So coming to the coding part, I am going to use Keras deep learning library in python to build CNN(Convolutional Neural Network).\n",
    "\n",
    "The process of building a Convolutional Neural Network always involves four major steps:\n",
    "\n",
    "Convolution.\n",
    "Pooling.\n",
    "Flattening.\n",
    "Full connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART A - DEEP LEARNING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have imported Sequential from keras.models, to initialise my neural network model as a sequential network. There are two basic ways of initialising a neural network, either by a sequence of layers or as a graph.\n",
    "\n",
    "I have imported Conv2D from keras.layers, this is to perform the convolution operation i.e the first step of a CNN, on the training images. Since we are working on images here, which a basically 2 Dimensional arrays, we’re using Convolution 2-D. For videos we can use convolution 3D.\n",
    "\n",
    "I have imported MaxPooling2D from keras.layers, which is used for pooling operation, that is the step — 2 in the process of building a cnn. For building this particular neural network, we are using a Maxpooling function, there exist different types of pooling operations like Min Pooling, Mean Pooling, etc. Here in MaxPooling we need the maximum value pixel from the respective region of interest.\n",
    "\n",
    "Flatten is used for flattening, it is the process of converting resultant 2D array into a single long continuos linear vector.\n",
    "\n",
    "Dense is used to perform full connection of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()    #Creating an object of the sequential class below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART B - ACTIVATION FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activation function which is being used here is that of ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s break down the above code function by function. I took the sequential object , then I added a convolution layer by using the “Conv2D” function. The Conv2D function is taking 4 arguments, the first is the number of filters i.e 32 here, the second argument is the shape each filter is going to be i.e 3x3 here, the third is the input shape and the type of image(RGB or Black and White)of each image i.e the input image our CNN is going to be taking is of a 64x64 resolution and “3” stands for RGB, which is a colour img, the fourth argument is the activation function we want to use, here ‘relu’ stands for a rectifier function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand pooling I recommend to use the following link: http://ufldl.stanford.edu/tutorial/supervised/Pooling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I am basically doing here is taking the 2-D array, i.e pooled image pixels and converting them to a one dimensional single vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 128, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this step we need to create a fully connected layer, and to this layer we are going to connect the set of nodes we got after the flattening step, these nodes will act as an input layer to these fully-connected layers.\n",
    "\n",
    "‘units’ is where we define the number of nodes that should be present in this hidden layer, these units value will be always between the number of input nodes and the output nodes but the art of choosing the most optimal number of nodes can be achieved only through experimental tries. Though it’s a common practice to use a power of 2. And the activation function will be a rectifier function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART C & E- COST FUNCTION & GRADIENT ESTIMATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function which is being used here is Cross-Entropy. Since, the number of classes to predict is only two, the type of cross-entropy is binary.\n",
    "The optimization function to be used for estimating the highest probability to classify correctly is \"ADAM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Optimizer parameter is to choose the stochastic gradient descent algorithm. Loss parameter is to choose the loss function. The metrics parameter is to choose the performance metric.\n",
    "\n",
    "So before we fit our images to the neural network, we need to perform some image augmentations on them, which is basically synthesising the training data. This step is done to prevent overfitting of the model. I am going to do this using keras.preprocessing library for doing the synthesising part as well as to prepare the training set and the test set of images that are present in a properly structured directories, where the directory’s name is take as the label of all the images present in it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making new predictions from our trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test_image holds the image that needs to be tested on the CNN. Preparing the image to be sent into the model by converting its resolution to 64x64 as the model only excepts that resolution. Then I am using predict() method on classifier object to get the prediction. As the prediction will be in a binary form, we will be receiving either a 1 or 0, which will represent a dog or a cat respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 229 images belonging to 2 classes.\n",
      "Found 20 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "shear_range = 0.2,\n",
    "zoom_range = 0.2,\n",
    "horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "training_set = train_datagen.flow_from_directory('assign4/train',\n",
    "target_size = (64, 64),\n",
    "batch_size = 32,\n",
    "class_mode = 'binary')\n",
    "test_set = test_datagen.flow_from_directory('assign4/test',\n",
    "target_size = (64, 64),\n",
    "batch_size = 32,\n",
    "class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fiting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART D - EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single epoch is a single step in training a neural network; in other words when a neural network is trained on every training samples only in one pass we say that one epoch is finished. So training process should consist more than one epochs.In this case we have defined 2 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "400/400 [==============================] - 152s 379ms/step - loss: 0.7375 - acc: 0.8845 - val_loss: 0.5910 - val_acc: 0.8000\n",
      "Epoch 2/2\n",
      "400/400 [==============================] - 163s 407ms/step - loss: 0.0276 - acc: 0.9904 - val_loss: 0.6563 - val_acc: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f05a0c8940>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "steps_per_epoch = 400,\n",
    "epochs = 2,\n",
    "validation_data = test_set,\n",
    "validation_steps = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib.inline\n",
    "fig=plt.figure()\n",
    "plt.plot(display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dunkin donuts\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "path = \"abc.png\"\n",
    "#imageID+=1\n",
    "test_image = image.load_img(path, target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = load.predict(test_image)\n",
    "#training_set.class_indices\n",
    "#print(training_set.class_indices)\n",
    "\n",
    "if result[0]==0:\n",
    "    print('dunkin donuts')\n",
    "else:\n",
    "    print('starbucks')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "starCount = 0\n",
    "ddCount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of predicted Dunkin Donuts images:  8\n"
     ]
    }
   ],
   "source": [
    "directoryPath = 'assign4/test/dunkin donuts'\n",
    "for dire,subdir,files in os.walk(directoryPath):\n",
    "    for i in files:\n",
    "        path = 'assign4/test/dunkin donuts/' + str(i)\n",
    "        test_image = image.load_img(path, target_size = (64, 64))\n",
    "        test_image = image.img_to_array(test_image)\n",
    "        test_image = np.expand_dims(test_image, axis = 0)\n",
    "        result = load.predict(test_image)\n",
    "        if result[0]==0:\n",
    "            ddCount += 1\n",
    "            #print('dunkin donuts')\n",
    "            flag = 0\n",
    "        else:\n",
    "            starCount += 1\n",
    "            #print('starbucks')\n",
    "            flag = 1\n",
    "\n",
    "\n",
    "            \n",
    "if flag ==0:\n",
    "    print('No. of predicted Dunkin Donuts images: ', ddCount)\n",
    "else:\n",
    "    print('No. of predicted Starbucks images: ', starCount)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(starCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(ddCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART F - NETWORK ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 813,217\n",
      "Trainable params: 813,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save(\"C:/Users/chels/bdiaprojfinal.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "load = load_model('C://Users//chels//bigdatafinalproject//bdiaprojfinal.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIT License\n",
    "\n",
    "Copyright (c) 2018, Karan Barai, Gauravi Chaudhari, Pranav Swaminathan\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
